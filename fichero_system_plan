# üìÑ Fichero Processing System: Full System Design (Detailed Markdown Version)

---

# üí™ Project Goal

We are building **Fichero**, a scalable, resilient document processing system designed to:

* Handle tens of thousands of files (up to 61,000+)
* Organize documents into **folders** (e.g., legal cases)
* Process documents **independently and in parallel**
* Post-process **entire folders** when files are complete
* Be controllable via **CLI**
* Be **reliable, fault-tolerant, and recoverable**
* **Scale** cleanly with CPUs

---

# üîç Architecture Overview

| Layer                      | Role                                              |
| :------------------------- | :------------------------------------------------ |
| CLI (fichero_cli.py)      | Parses inputs, manages workflow execution         |
| Controller (controller.py) | Manages file processing and worker pools          |
| Monitor (monitor.py)       | Watches manifest.jsonl for folder completion      |
| manifest.jsonl            | Central file recording per-file status            |

---

# üåê Detailed Workflow

1. User selects a workflow and configuration via CLI.
2. CLI invokes **Controller**, which:
   * Scans the selected folder.
   * Processes files based on workflow steps.
   * Manages parallel execution with worker pools.
3. Each **processing step** updates **manifest.jsonl** with file progress.
4. **Separate Monitor process**:
   * Reads manifest.jsonl every few seconds.
   * Groups files by folder.
   * Triggers **folder-level processing** once all files in a folder are "done".

---

# üìÇ Key Files and Roles

| File                     | Purpose                                          |
| :----------------------- | :----------------------------------------------- |
| fichero_cli.py          | Command-line interface frontend                  |
| controller.py            | Manages file processing and worker pools         |
| monitor.py               | Separate process that monitors folder completion |
| steps/rotate.py          | Rotate image task                                |
| steps/enhance.py         | Image enhancement task                           |
| steps/segment.py         | Document segmentation task                       |
| steps/ocr.py             | OCR task                                         |
| steps/clean.py           | Cleaning/postprocessing task                     |
| steps/folder_merge.py    | Merge texts per folder                           |
| steps/folder_pdf.py      | Create final PDFs                                |
| steps/folder_archive.py  | Zip/Archive folder                               |
| jsonl_manager.py         | Safe read/write operations for manifest.jsonl    |

---

# üìö manifest.jsonl Format

Each line is one file:

```json
{
  "input_path": "/cases/case001/page_001.jpg",
  "folder": "case001",
  "rotation": 90,
  "enhanced": "/cases/case001/enhanced_page_001.jpg",
  "segments": [...],
  "transcription": "Extracted text...",
  "status": "done"
}
```

Fields:
* `input_path`: original file path
* `folder`: folder (case) name
* `status`: task completion status ("done", "error", etc.)

---

# üåÄ File-Level Processing (per file)

Each file is processed through the workflow steps:

```text
Rotate ‚ûî Enhance ‚ûî Segment ‚ûî OCR ‚ûî Clean
```

* Steps can run sequentially or in parallel based on configuration
* Progress is recorded after each step
* Error handling and retries are managed per step

---

# üåÄ Folder-Level Processing (per folder)

When all files in a folder are complete:

```text
Merge Transcriptions ‚ûî Create PDF ‚ûî Archive Folder
```

* The Monitor triggers folder-level processing
* Folder-level actions are reliable and sequential

---

# üöÄ Parallelism and Scaling

| Problem                             | Solution                                                    |
| :---------------------------------- | :---------------------------------------------------------- |
| 61,000+ files?                      | Async processing with worker pools                          |
| Writing conflicts in manifest.jsonl? | Safe concurrent writes with jsonl_manager                   |
| Folder needs to wait?               | Monitor watches and triggers folder processing              |
| Slow steps?                         | Fine, because each file is independent                      |
| CPU scaling?                        | Dynamic worker count based on system resources              |

**RAM usage?**
* Loading 61k file entries = ~200-500 MB RAM
* Fine on modern systems

---

# üèãÔ∏è Control Flow Diagram

```
[CLI]
   ‚îî‚îÄ‚îÄ Launches Controller ‚îÄ‚îÄ‚îî‚îÄ‚îÄ Process Files
                                    ‚îî‚îÄ‚îÄ Manage Worker Pools
[Monitor]
   ‚îî‚îÄ‚îÄ Watches manifest.jsonl
           ‚îî‚îÄ‚îÄ Triggers Folder Processing when Ready
```

---

# ‚ú® Summary in One Sentence

> **Fichero** processes files through configurable workflows, manages parallel execution with worker pools, monitors per-folder completion via manifest.jsonl, and triggers final folder processing automatically, all controlled through a clean CLI.

---

# üõ†Ô∏è Immediate Next Build Steps

1. **Implement processing steps**:
   - rotate.py
   - enhance.py
   - segment.py
   - ocr.py
   - clean.py

2. **Implement folder-level processing**:
   - folder_merge.py
   - folder_pdf.py
   - folder_archive.py

3. **Test with sample documents**:
   - Create test documents folder
   - Run through complete workflow
   - Verify parallel processing
   - Check folder completion

---

# üîç Notes for Implementation

* Focus on **clean async processing** with worker pools
* Focus on **file-level independence** + **folder-level post-processing**
* Use **safe concurrent writes** for manifest.jsonl updates
* Optimize **worker count** based on system resources
* Prepare for **batch processing** if needed for speed

---

# üèÜ You Are Now Building a Production-Ready Processing System!

Once implemented, **Fichero** will:

* Process tens of thousands of documents efficiently
* Scale across CPUs
* Be crash-recoverable
* Be cross-platform (macOS, Linux, Windows)
* Have a clean CLI for automation

---

# üöÄ Let's Build It!

# Notes
Completed: 
- jsonl_manager.py: Safe read/write operations for manifest.jsonl
- fichero_cli.py: CLI interface with workflow management
- async_controller.py: File processing and worker management
- folder_monitor.py: Folder completion monitoring

